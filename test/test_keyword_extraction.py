#!/usr/bin/env python3
"""
æµ‹è¯•AIå…³é”®è¯æå–åŠŸèƒ½
"""

import sys
import os
sys.path.append('src')

def test_keyword_extraction():
    """æµ‹è¯•å…³é”®è¯æå–åŠŸèƒ½"""
    print("=== æµ‹è¯•AIå…³é”®è¯æå–åŠŸèƒ½ ===\n")
    
    try:
        from keyword_extractor import keyword_extractor
        print("âœ… å…³é”®è¯æå–å™¨å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•å•æ¡æ–‡æœ¬æå–
    print("\nğŸ§ª æµ‹è¯•å•æ¡æ–‡æœ¬æå–...")
    test_text = "Today we will discuss artificial intelligence and machine learning. These technologies are becoming increasingly important in our daily lives."
    
    keywords = keyword_extractor.extract_keywords_from_text(test_text)
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text}")
    print(f"ğŸ¯ æå–ç»“æœ: {len(keywords)} ä¸ªå…³é”®è¯")
    
    for i, keyword in enumerate(keywords, 1):
        print(f"  {i}. {keyword['key_word']} {keyword.get('phonetic_symbol', '')} - {keyword.get('explain_text', '')}")
    
    # æµ‹è¯•å­—å¹•æ‰¹é‡æå–
    print("\nğŸ§ª æµ‹è¯•å­—å¹•æ‰¹é‡æå–...")
    mock_subtitles = [
        {
            'id': 1,
            'english_text': 'Hello everyone, welcome to our artificial intelligence course.',
            'chinese_text': 'å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„äººå·¥æ™ºèƒ½è¯¾ç¨‹ã€‚'
        },
        {
            'id': 2,
            'english_text': 'Machine learning is a subset of artificial intelligence.',
            'chinese_text': 'æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ã€‚'
        },
        {
            'id': 3,
            'english_text': 'Deep learning algorithms can process vast amounts of data.',
            'chinese_text': 'æ·±åº¦å­¦ä¹ ç®—æ³•å¯ä»¥å¤„ç†å¤§é‡æ•°æ®ã€‚'
        }
    ]
    
    print(f"ğŸ“š æ¨¡æ‹Ÿå­—å¹•: {len(mock_subtitles)} æ¡")
    
    # ä½¿ç”¨æ‰¹é‡æå–æ¨¡å¼
    batch_keywords = keyword_extractor.batch_extract_with_context(mock_subtitles, batch_size=2)
    print(f"ğŸ‰ æ‰¹é‡æå–ç»“æœ: {len(batch_keywords)} ä¸ªå…³é”®è¯")
    
    for i, keyword in enumerate(batch_keywords, 1):
        print(f"  {i}. [{keyword.get('subtitle_id')}] {keyword['key_word']} {keyword.get('phonetic_symbol', '')} - {keyword.get('explain_text', '')}")
    
    print("\nâœ… å…³é”®è¯æå–åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("ğŸ’¡ ç°åœ¨å¯ä»¥åœ¨æ•°æ®åº“ç®¡ç†ç•Œé¢ä½¿ç”¨AIæå–å…³é”®è¯åŠŸèƒ½äº†ï¼")
    
    return True

def test_database_integration():
    """æµ‹è¯•æ•°æ®åº“é›†æˆ"""
    print("\n=== æµ‹è¯•æ•°æ®åº“é›†æˆ ===")
    
    try:
        from database import db_manager
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ•°æ®
        stats = db_manager.get_statistics()
        print(f"ğŸ“Š å½“å‰æ•°æ®åº“çŠ¶æ€:")
        print(f"  - åª’ä½“ç³»åˆ—: {stats['series_count']}")
        print(f"  - å­—å¹•æ¡ç›®: {stats['subtitle_count']}")
        print(f"  - å…³é”®è¯æ•°: {stats['keyword_count']}")
        
        if stats['series_count'] > 0:
            # è·å–ç¬¬ä¸€ä¸ªç³»åˆ—çš„å­—å¹•
            all_series = db_manager.get_series()
            first_series = all_series[0]
            series_id = first_series['id']
            
            subtitles = db_manager.get_subtitles(series_id)
            print(f"\nğŸ“ ç³»åˆ— {series_id} æœ‰ {len(subtitles)} æ¡å­—å¹•")
            
            if len(subtitles) > 0:
                print("ğŸ¯ å¯ä»¥åœ¨æ•°æ®åº“ç®¡ç†ç•Œé¢ä½¿ç”¨AIæå–åŠŸèƒ½")
                print(f"ğŸ”— è®¿é—®: http://localhost:7861")
                print(f"ğŸ“‹ åœ¨å…³é”®è¯åº“é¡µé¢è¾“å…¥ç³»åˆ—ID: {series_id}")
                print("ğŸ¤– ç‚¹å‡» 'AIæå–å…³é”®è¯' æŒ‰é’®")
            else:
                print("âš ï¸ è¯¥ç³»åˆ—æ²¡æœ‰å­—å¹•æ•°æ®")
        else:
            print("ğŸ’¡ å»ºè®®å…ˆå¤„ç†ä¸€äº›éŸ³è§†é¢‘æ–‡ä»¶ç”Ÿæˆå­—å¹•ï¼Œç„¶åå†æµ‹è¯•AIæå–åŠŸèƒ½")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    test_keyword_extraction()
    test_database_integration() 