#!/usr/bin/env python3
"""
æµ‹è¯•è¯­ä¹‰å•å…ƒå­—å¹•åˆ‡åˆ†åŠŸèƒ½
"""

import sys
import os
sys.path.append('src')

from subtitle_splitter import SubtitleSplitter, split_subtitle_chunks

def test_semantic_splitting():
    """æµ‹è¯•è¯­ä¹‰å•å…ƒåˆ‡åˆ†"""
    print("=== æµ‹è¯•è¯­ä¹‰å•å…ƒå­—å¹•åˆ‡åˆ† ===\n")
    
    # åˆ›å»ºåˆ‡åˆ†å™¨
    splitter = SubtitleSplitter()
    
    # æµ‹è¯•ç”¨æˆ·æä¾›çš„ä¾‹å­
    print("ğŸ§ª æµ‹è¯•ç”¨æˆ·æä¾›çš„ä¾‹å­...")
    english_text = "about midnight and it was very dark and very quiet. We got to the shop and we..."
    chinese_text = "å¤§çº¦åœ¨åˆå¤œæ—¶åˆ†ï¼Œå››å‘¨éå¸¸é»‘æš—ï¼Œä¹Ÿéå¸¸å®‰é™ã€‚æˆ‘ä»¬åˆ°äº†å•†åº—ï¼Œæ¥ç€æˆ‘ä»¬â€¦â€¦"
    
    # æµ‹è¯•å•è¯­åˆ‡åˆ†
    print("è‹±æ–‡åŸæ–‡:", english_text)
    english_segments = splitter._split_by_semantic_units(english_text)
    print("è‹±æ–‡è¯­ä¹‰å•å…ƒåˆ‡åˆ†ç»“æœ:")
    for i, segment in enumerate(english_segments, 1):
        print(f"  {i}. {segment}")
    
    print("\nä¸­æ–‡åŸæ–‡:", chinese_text)
    chinese_segments = splitter._split_chinese_by_english_units(chinese_text, english_segments)
    print("ä¸­æ–‡å¯¹åº”åˆ‡åˆ†ç»“æœ:")
    for i, segment in enumerate(chinese_segments, 1):
        print(f"  {i}. {segment}")
    
    print("\n" + "="*60 + "\n")
    
    # æµ‹è¯•åŒè¯­æ—¶é—´æˆ³åˆ†é…
    print("ğŸ§ª æµ‹è¯•åŒè¯­æ—¶é—´æˆ³åˆ†é…...")
    bilingual_segments = splitter.split_bilingual_text(english_text, chinese_text, 0.0, 10.0)
    
    print("åŒè¯­åˆ‡åˆ†ç»“æœï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰:")
    for i, segment in enumerate(bilingual_segments, 1):
        start_time = segment['timestamp'][0]
        end_time = segment['timestamp'][1]
        english = segment['english']
        chinese = segment['chinese']
        print(f"  {i}. [{start_time:.1f}s - {end_time:.1f}s]")
        print(f"     EN: {english}")
        print(f"     CN: {chinese}")
    
    print("\n" + "="*60 + "\n")
    
    # æµ‹è¯•å®Œæ•´çš„å­—å¹•å—åˆ‡åˆ†
    print("ğŸ§ª æµ‹è¯•å®Œæ•´å­—å¹•å—åˆ‡åˆ†...")
    
    # æ¨¡æ‹ŸåŒè¯­å­—å¹•å—
    mock_bilingual_chunks = [
        {
            "english": "Hello everyone and welcome to our channel. Today we're going to talk about artificial intelligence.",
            "chinese": "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„é¢‘é“ã€‚ä»Šå¤©æˆ‘ä»¬è¦è®¨è®ºäººå·¥æ™ºèƒ½ã€‚",
            "timestamp": [0.0, 6.0]
        },
        {
            "english": "AI has many applications and it's becoming very important in our daily lives.",
            "chinese": "äººå·¥æ™ºèƒ½æœ‰å¾ˆå¤šåº”ç”¨ï¼Œå®ƒåœ¨æˆ‘ä»¬çš„æ—¥å¸¸ç”Ÿæ´»ä¸­å˜å¾—éå¸¸é‡è¦ã€‚",
            "timestamp": [6.5, 12.0]
        }
    ]
    
    split_result = split_subtitle_chunks(mock_bilingual_chunks, is_bilingual=True)
    
    print("å®Œæ•´åŒè¯­å­—å¹•åˆ‡åˆ†ç»“æœ:")
    for i, chunk in enumerate(split_result, 1):
        start_time = chunk['timestamp'][0]
        end_time = chunk['timestamp'][1]
        english = chunk['english']
        chinese = chunk['chinese']
        print(f"{i}. [{start_time:.1f}s - {end_time:.1f}s]")
        print(f"   EN: {english}")
        print(f"   CN: {chinese}")
        print()
    
    print("âœ… è¯­ä¹‰å•å…ƒåˆ‡åˆ†æµ‹è¯•å®Œæˆï¼")
    print("ğŸ’¡ ç°åœ¨å­—å¹•æŒ‰è¯­ä¹‰å•å…ƒåˆ‡åˆ†ï¼Œä¸­è‹±æ–‡èƒ½å¤Ÿç²¾ç¡®å¯¹åº”ï¼")
    
    return True

if __name__ == "__main__":
    test_semantic_splitting() 