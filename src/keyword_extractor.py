#!/usr/bin/env python3
"""
å…³é”®è¯æå–æ¨¡å—
ä½¿ç”¨OpenAI APIåˆ†æå­—å¹•æ–‡æœ¬ï¼Œæå–é€‚åˆå¤§å­¦ç”Ÿè‹±è¯­æ°´å¹³çš„é‡ç‚¹è¯æ±‡
"""

import re
import json
from typing import List, Dict, Tuple
from openai import OpenAI
from logger import LOG

class KeywordExtractor:
    """å…³é”®è¯æå–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æå–å™¨"""
        # ä½¿ç”¨å’Œç¿»è¯‘æ¨¡å—ç›¸åŒçš„é…ç½®
        from openai_translate import client
        self.client = client
        
        # æç¤ºè¯æ¨¡æ¿
        self.prompt_template = """æˆ‘æ˜¯ä¸€åå¤§å­¦ç”Ÿï¼Œè‹±è¯­æ°´å¹³åœ¨å…­çº§å·¦å³ã€‚è¯·åˆ†æä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ï¼Œæå–å‡ºå¯¹æˆ‘è¿™ä¸ªæ°´å¹³æ¥è¯´æ¯”è¾ƒé‡è¦çš„è¯æ±‡ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼Œæ¯ä¸ªè¯æ±‡ä¸€è¡Œï¼š
è¯æ±‡ /éŸ³æ ‡/ ä¸­æ–‡è§£é‡Š

ä¾‹å¦‚ï¼š
come up with /kÊŒm ÊŒp wÉªÃ°/ æƒ³å‡ºï¼Œæå‡º
artificial /ËŒÉ‘ËtÉªËˆfÉªÊƒÉ™l/ adj. äººå·¥çš„ï¼Œäººé€ çš„

è¦æ±‚ï¼š 
1. åªæå–è€ƒç ”ã€é›…æ€ã€æ‰˜ç¦ã€GREèŒƒå›´å†…çš„å•è¯
2. ä¸è¦æå–ç®€å•çš„è¯æ±‡
3. åŒ…æ‹¬çŸ­è¯­å’Œæ­é…
4. éŸ³æ ‡ä½¿ç”¨å›½é™…éŸ³æ ‡æ ‡å‡†
5. ä¸­æ–‡è§£é‡Šç®€æ´å‡†ç¡®, è¯æ€§è¦æ ‡æ³¨

å¾…åˆ†ææ–‡æœ¬ï¼š
{text}

è¯·æå–é‡ç‚¹è¯æ±‡ï¼š"""
        
        LOG.info("ğŸ”§ å…³é”®è¯æå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def extract_keywords_from_text(self, text: str) -> List[Dict]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯
        
        å‚æ•°:
        - text: è‹±æ–‡æ–‡æœ¬
        
        è¿”å›:
        - List[Dict]: å…³é”®è¯åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« word, phonetic, explanation
        """
        if not text.strip():
            return []
        
        try:
            LOG.info(f"ğŸ” æ­£åœ¨åˆ†ææ–‡æœ¬: {text[:50]}...")
            
            # æ„å»ºæç¤ºè¯
            prompt = self.prompt_template.format(text=text.strip())
            
            # è°ƒç”¨OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‹±è¯­æ•™å¸ˆï¼Œä¸“é—¨å¸®åŠ©å¤§å­¦ç”Ÿå­¦ä¹ è‹±è¯­è¯æ±‡ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            keywords = self._parse_keywords_response(content)
            
            LOG.info(f"âœ… æå–åˆ° {len(keywords)} ä¸ªå…³é”®è¯")
            return keywords
            
        except Exception as e:
            LOG.error(f"âŒ å…³é”®è¯æå–å¤±è´¥: {e}")
            return []
    
    def _parse_keywords_response(self, response_text: str) -> List[Dict]:
        """
        è§£æAIå“åº”ï¼Œæå–å…³é”®è¯ä¿¡æ¯
        
        å‚æ•°:
        - response_text: AIè¿”å›çš„æ–‡æœ¬
        
        è¿”å›:
        - List[Dict]: è§£æåçš„å…³é”®è¯åˆ—è¡¨
        """
        keywords = []
        
        # æŒ‰è¡Œåˆ†å‰²
        lines = response_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ ¼å¼ï¼šè¯æ±‡ /éŸ³æ ‡/ è§£é‡Š
            pattern = r'^(.+?)\s+/([^/]+)/\s+(.+)$'
            match = re.match(pattern, line)
            
            if match:
                word = match.group(1).strip()
                phonetic = match.group(2).strip()
                explanation = match.group(3).strip()
                
                # è·å–COCAè¯é¢‘æ’å
                from coca_lookup import coca_lookup
                coca_rank = coca_lookup.get_frequency_rank(word)
                
                keywords.append({
                    'key_word': word,
                    'phonetic_symbol': f"/{phonetic}/",
                    'explain_text': explanation,
                    'coca': coca_rank
                })
            else:
                # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
                if '/' in line and len(line.split()) >= 2:
                    parts = line.split()
                    word_part = parts[0]
                    remaining = ' '.join(parts[1:])
                    
                    # æŸ¥æ‰¾éŸ³æ ‡
                    phonetic_match = re.search(r'/([^/]+)/', remaining)
                    if phonetic_match:
                        phonetic = phonetic_match.group(1)
                        explanation = remaining.replace(f"/{phonetic}/", "").strip()
                        
                        # è·å–COCAè¯é¢‘æ’å
                        from coca_lookup import coca_lookup
                        coca_rank = coca_lookup.get_frequency_rank(word_part)
                        
                        keywords.append({
                            'key_word': word_part,
                            'phonetic_symbol': f"/{phonetic}/",
                            'explain_text': explanation,
                            'coca': coca_rank
                        })
        
        return keywords
    
    def extract_keywords_from_subtitles(self, subtitles: List[Dict]) -> List[Dict]:
        """
        ä»å­—å¹•åˆ—è¡¨ä¸­æå–å…³é”®è¯
        
        å‚æ•°:
        - subtitles: å­—å¹•åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« id, english_text ç­‰
        
        è¿”å›:
        - List[Dict]: å…³é”®è¯åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« subtitle_id, key_word, phonetic_symbol, explain_text
        """
        all_keywords = []
        
        LOG.info(f"ğŸ¯ å¼€å§‹ä» {len(subtitles)} æ¡å­—å¹•ä¸­æå–å…³é”®è¯")
        
        for i, subtitle in enumerate(subtitles):
            subtitle_id = subtitle.get('id')
            english_text = subtitle.get('english_text', '').strip()
            
            if not english_text:
                continue
            
            LOG.info(f"ğŸ“ å¤„ç†å­—å¹• {i+1}/{len(subtitles)}: ID={subtitle_id}")
            
            # æå–å½“å‰å­—å¹•çš„å…³é”®è¯
            keywords = self.extract_keywords_from_text(english_text)
            
            # æ·»åŠ å­—å¹•ID
            for keyword in keywords:
                keyword['subtitle_id'] = subtitle_id
                all_keywords.append(keyword)
        
        LOG.info(f"ğŸ‰ æ€»è®¡æå–åˆ° {len(all_keywords)} ä¸ªå…³é”®è¯")
        return all_keywords
    
    def batch_extract_with_context(self, subtitles: List[Dict], batch_size: int = 5) -> List[Dict]:
        """
        æ‰¹é‡æå–å…³é”®è¯ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
        
        å‚æ•°:
        - subtitles: å­—å¹•åˆ—è¡¨
        - batch_size: æ‰¹æ¬¡å¤§å°
        
        è¿”å›:
        - List[Dict]: å…³é”®è¯åˆ—è¡¨
        """
        all_keywords = []
        
        LOG.info(f"ğŸ“¦ æ‰¹é‡æå–æ¨¡å¼: {len(subtitles)} æ¡å­—å¹•ï¼Œæ‰¹æ¬¡å¤§å°={batch_size}")
        
        for i in range(0, len(subtitles), batch_size):
            batch = subtitles[i:i+batch_size]
            
            # åˆå¹¶å½“å‰æ‰¹æ¬¡çš„æ–‡æœ¬
            combined_text = " ".join([sub.get('english_text', '') for sub in batch if sub.get('english_text')])
            
            if not combined_text.strip():
                continue
            
            LOG.info(f"ğŸ“ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch)} æ¡å­—å¹•")
            
            # æå–å…³é”®è¯
            keywords = self.extract_keywords_from_text(combined_text)
            
            # ä¸ºæ¯ä¸ªå…³é”®è¯æ‰¾åˆ°æœ€åŒ¹é…çš„å­—å¹•ID
            for keyword in keywords:
                best_subtitle_id = self._find_best_matching_subtitle(
                    keyword['key_word'], batch
                )
                keyword['subtitle_id'] = best_subtitle_id
                all_keywords.append(keyword)
        
        LOG.info(f"ğŸ‰ æ‰¹é‡æå–å®Œæˆ: {len(all_keywords)} ä¸ªå…³é”®è¯")
        return all_keywords
    
    def _find_best_matching_subtitle(self, keyword: str, subtitles: List[Dict]) -> int:
        """
        ä¸ºå…³é”®è¯æ‰¾åˆ°æœ€åŒ¹é…çš„å­—å¹•
        
        å‚æ•°:
        - keyword: å…³é”®è¯
        - subtitles: å­—å¹•åˆ—è¡¨
        
        è¿”å›:
        - int: æœ€åŒ¹é…çš„å­—å¹•ID
        """
        keyword_lower = keyword.lower()
        
        # æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„å­—å¹•
        for subtitle in subtitles:
            text = subtitle.get('english_text', '').lower()
            if keyword_lower in text:
                return subtitle.get('id')
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå­—å¹•çš„ID
        return subtitles[0].get('id') if subtitles else None

# å…¨å±€æå–å™¨å®ä¾‹
keyword_extractor = KeywordExtractor() 