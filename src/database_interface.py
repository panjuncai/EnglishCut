#!/usr/bin/env python3
"""
æ•°æ®åº“ç®¡ç†ç•Œé¢
æä¾›æŸ¥çœ‹å’Œç®¡ç†ä¿å­˜çš„åª’ä½“ã€å­—å¹•å’Œå…³é”®è¯çš„Webç•Œé¢
"""

import os
# æ¸…é™¤å¯èƒ½å¹²æ‰° Gradio å¯åŠ¨çš„ä»£ç†ç¯å¢ƒå˜é‡
proxy_vars = ['http_proxy', 'https_proxy', 'HTTP_PROXY', 'HTTPS_PROXY']
for var in proxy_vars:
    if var in os.environ:
        print(f"ğŸ§¹ æ¸…é™¤ä»£ç†ç¯å¢ƒå˜é‡: {var}={os.environ[var]}")
        del os.environ[var]

import gradio as gr
import pandas as pd
from database import db_manager
from logger import LOG
from typing import List, Dict

def create_database_interface():
    """åˆ›å»ºæ•°æ®åº“ç®¡ç†ç•Œé¢"""
    
    with gr.Blocks(title="æ•°æ®åº“ç®¡ç†", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# ğŸ“Š æ•°æ®åº“ç®¡ç†ç•Œé¢")
        
        # ç»Ÿè®¡ä¿¡æ¯é¢æ¿
        with gr.Row():
            with gr.Column():
                stats_display = gr.Markdown("## ğŸ“ˆ æ•°æ®ç»Ÿè®¡\nåŠ è½½ä¸­...")
        
        # é€‰é¡¹å¡ç•Œé¢
        with gr.Tabs():
            # åª’ä½“ç³»åˆ—ç®¡ç†
            with gr.TabItem("ğŸ¬ åª’ä½“ç³»åˆ—"):
                with gr.Row():
                    with gr.Column(scale=3):
                        series_table = gr.Dataframe(
                            headers=["ID", "åç§°", "æ–‡ä»¶ç±»å‹", "æ—¶é•¿(ç§’)", "çƒ§åˆ¶è§†é¢‘å", "çƒ§åˆ¶è·¯å¾„", "åˆ›å»ºæ—¶é—´"],
                            datatype=["number", "str", "str", "number", "str", "str", "str"],
                            label="åª’ä½“ç³»åˆ—åˆ—è¡¨",
                            interactive=False,
                            wrap=True
                        )
                    
                    with gr.Column(scale=1):
                        refresh_series_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", variant="secondary")
                        selected_series_id = gr.Number(label="é€‰æ‹©ç³»åˆ—ID", value=None, precision=0)
                        view_subtitles_btn = gr.Button("ğŸ“ æŸ¥çœ‹å­—å¹•", variant="primary")
                        delete_series_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤ç³»åˆ—", variant="stop")
                        
                        # çƒ§åˆ¶è§†é¢‘ä¿¡æ¯æ›´æ–°
                        with gr.Group():
                            gr.Markdown("### ğŸ¬ æ›´æ–°çƒ§åˆ¶è§†é¢‘ä¿¡æ¯")
                            update_series_id = gr.Number(label="ç³»åˆ—ID", precision=0)
                            update_new_name = gr.Textbox(label="çƒ§åˆ¶è§†é¢‘åç§°", placeholder="ä¾‹: output_with_subtitles.mp4")
                            update_new_path = gr.Textbox(label="çƒ§åˆ¶è§†é¢‘è·¯å¾„", placeholder="ä¾‹: /path/to/output_video.mp4")
                            update_video_btn = gr.Button("ğŸ’¾ æ›´æ–°ä¿¡æ¯", variant="primary")
                            update_result = gr.Textbox(label="æ›´æ–°ç»“æœ", interactive=False)
            
            # å­—å¹•ç®¡ç†
            with gr.TabItem("ğŸ“ å­—å¹•ç®¡ç†"):
                with gr.Row():
                    series_id_input = gr.Number(label="ç³»åˆ—ID", value=None, precision=0)
                    load_subtitles_btn = gr.Button("åŠ è½½å­—å¹•", variant="primary")
                
                subtitles_table = gr.Dataframe(
                    headers=["ID", "å¼€å§‹æ—¶é—´", "ç»“æŸæ—¶é—´", "è‹±æ–‡æ–‡æœ¬", "ä¸­æ–‡æ–‡æœ¬"],
                    datatype=["number", "number", "number", "str", "str"],
                    label="å­—å¹•åˆ—è¡¨",
                    interactive=False,
                    wrap=True
                )
            
            # å…³é”®è¯ç®¡ç†
            with gr.TabItem("ğŸ“š å…³é”®è¯åº“"):
                with gr.Row():
                    with gr.Column():
                        search_keyword_input = gr.Textbox(label="æœç´¢å…³é”®è¯", placeholder="è¾“å…¥è¦æœç´¢çš„å•è¯...")
                        search_btn = gr.Button("ğŸ” æœç´¢", variant="primary")
                    
                    with gr.Column():
                        keyword_series_id = gr.Number(label="æŒ‰ç³»åˆ—IDæŸ¥çœ‹", value=None, precision=0)
                        with gr.Row():
                            load_keywords_btn = gr.Button("ğŸ“š åŠ è½½å…³é”®è¯", variant="secondary")
                            extract_keywords_btn = gr.Button("ğŸ¤– AIæå–å…³é”®è¯", variant="primary")
                
                keywords_table = gr.Dataframe(
                    headers=["ID", "å•è¯", "éŸ³æ ‡", "è§£é‡Š", "æ¥æºç³»åˆ—", "æ—¶é—´æ®µ"],
                    datatype=["number", "str", "str", "str", "str", "str"],
                    label="å…³é”®è¯åˆ—è¡¨",
                    interactive=False,
                    wrap=True
                )
                
                # æ‰‹åŠ¨æ·»åŠ å…³é”®è¯
                with gr.Row():
                    gr.Markdown("### â• æ‰‹åŠ¨æ·»åŠ å…³é”®è¯")
                
                with gr.Row():
                    with gr.Column():
                        add_subtitle_id = gr.Number(label="å­—å¹•ID", precision=0)
                        add_keyword = gr.Textbox(label="å•è¯")
                    with gr.Column():
                        add_phonetic = gr.Textbox(label="éŸ³æ ‡ï¼ˆå¯é€‰ï¼‰", placeholder="å¦‚: /ËˆÉªntÉ™ËŒnet/")
                        add_explanation = gr.Textbox(label="è§£é‡Š", placeholder="å•è¯çš„ä¸­æ–‡è§£é‡Š")
                
                add_keyword_btn = gr.Button("â• æ·»åŠ å…³é”®è¯", variant="primary")
                add_result = gr.Textbox(label="æ·»åŠ ç»“æœ", interactive=False)
                
                # AIæå–å…³é”®è¯çŠ¶æ€
                with gr.Row():
                    gr.Markdown("### ğŸ¤– AIå…³é”®è¯æå–")
                
                extract_status = gr.Textbox(label="æå–çŠ¶æ€", interactive=False, placeholder="ç­‰å¾…å¼€å§‹...")
                extract_progress = gr.Textbox(label="æå–è¿›åº¦", interactive=False)

        def update_statistics():
            """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
            try:
                stats = db_manager.get_statistics()
                
                stats_text = f"""## ğŸ“ˆ æ•°æ®ç»Ÿè®¡

ğŸ“ **åª’ä½“ç³»åˆ—**: {stats['series_count']} ä¸ª
ğŸ“ **å­—å¹•æ¡ç›®**: {stats['subtitle_count']} æ¡  
ğŸ“š **å…³é”®è¯æ•°**: {stats['keyword_count']} ä¸ª
ğŸ”¤ **ç‹¬ç‰¹å•è¯**: {stats['unique_words']} ä¸ª
â±ï¸ **æ€»æ—¶é•¿**: {stats['total_duration']:.1f} ç§’ ({stats['total_duration']/60:.1f} åˆ†é’Ÿ)
"""
                return stats_text
            except Exception as e:
                LOG.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
                return "## ğŸ“ˆ æ•°æ®ç»Ÿè®¡\nâŒ åŠ è½½å¤±è´¥"

        def load_series_list():
            """åŠ è½½åª’ä½“ç³»åˆ—åˆ—è¡¨"""
            try:
                series_list = db_manager.get_series()
                
                if not series_list:
                    return []
                
                # è½¬æ¢ä¸ºè¡¨æ ¼æ•°æ®
                table_data = []
                for series in series_list:
                    # å¤„ç†çƒ§åˆ¶è§†é¢‘ä¿¡æ¯çš„æ˜¾ç¤º
                    new_name = series.get('new_name', '') or 'æœªçƒ§åˆ¶'
                    new_path = series.get('new_file_path', '') or 'æœªè®¾ç½®'
                    
                    # æˆªæ–­è¿‡é•¿çš„è·¯å¾„æ˜¾ç¤º
                    if len(new_path) > 50:
                        new_path = new_path[:47] + '...'
                    
                    table_data.append([
                        series['id'],
                        series['name'],
                        series.get('file_type', 'æœªçŸ¥'),
                        series.get('duration', 0) or 0,
                        new_name,
                        new_path,
                        series['created_at']
                    ])
                
                return table_data
            except Exception as e:
                LOG.error(f"åŠ è½½ç³»åˆ—åˆ—è¡¨å¤±è´¥: {e}")
                return []

        def load_subtitles_by_series(series_id):
            """æ ¹æ®ç³»åˆ—IDåŠ è½½å­—å¹•"""
            if not series_id:
                return []
            
            try:
                subtitles = db_manager.get_subtitles(int(series_id))
                
                if not subtitles:
                    return []
                
                # è½¬æ¢ä¸ºè¡¨æ ¼æ•°æ®
                table_data = []
                for subtitle in subtitles:
                    table_data.append([
                        subtitle['id'],
                        round(subtitle['begin_time'], 2),
                        round(subtitle['end_time'], 2),
                        subtitle.get('english_text', '')[:100] + ('...' if len(subtitle.get('english_text', '')) > 100 else ''),
                        subtitle.get('chinese_text', '')[:100] + ('...' if len(subtitle.get('chinese_text', '')) > 100 else '')
                    ])
                
                return table_data
            except Exception as e:
                LOG.error(f"åŠ è½½å­—å¹•å¤±è´¥: {e}")
                return []

        def search_keywords_func(keyword):
            """æœç´¢å…³é”®è¯"""
            if not keyword.strip():
                return []
            
            try:
                results = db_manager.search_keywords(keyword.strip())
                
                if not results:
                    return []
                
                # è½¬æ¢ä¸ºè¡¨æ ¼æ•°æ®
                table_data = []
                for result in results:
                    time_range = f"{result.get('begin_time', 0):.1f}s - {result.get('end_time', 0):.1f}s"
                    table_data.append([
                        result['id'],
                        result['key_word'],
                        result.get('phonetic_symbol', ''),
                        result.get('explain_text', ''),
                        result.get('series_name', ''),
                        time_range
                    ])
                
                return table_data
            except Exception as e:
                LOG.error(f"æœç´¢å…³é”®è¯å¤±è´¥: {e}")
                return []

        def load_keywords_by_series(series_id):
            """æ ¹æ®ç³»åˆ—IDåŠ è½½å…³é”®è¯"""
            if not series_id:
                return []
            
            try:
                keywords = db_manager.get_keywords(series_id=int(series_id))
                
                if not keywords:
                    return []
                
                # è½¬æ¢ä¸ºè¡¨æ ¼æ•°æ®
                table_data = []
                for keyword in keywords:
                    time_range = f"{keyword.get('begin_time', 0):.1f}s - {keyword.get('end_time', 0):.1f}s"
                    table_data.append([
                        keyword['id'],
                        keyword['key_word'],
                        keyword.get('phonetic_symbol', ''),
                        keyword.get('explain_text', ''),
                        "",  # ç³»åˆ—åï¼ˆå› ä¸ºå·²ç»æŒ‰ç³»åˆ—ç­›é€‰ï¼‰
                        time_range
                    ])
                
                return table_data
            except Exception as e:
                LOG.error(f"åŠ è½½å…³é”®è¯å¤±è´¥: {e}")
                return []

        def update_video_info_func(series_id, new_name, new_path):
            """æ›´æ–°ç³»åˆ—çš„çƒ§åˆ¶è§†é¢‘ä¿¡æ¯"""
            if not series_id:
                return "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ç³»åˆ—ID"
            
            if not new_name.strip() and not new_path.strip():
                return "âŒ è¯·è‡³å°‘è¾“å…¥è§†é¢‘åç§°æˆ–è·¯å¾„ä¸­çš„ä¸€ä¸ª"
            
            try:
                success = db_manager.update_series_video_info(
                    int(series_id),
                    new_name=new_name.strip() if new_name.strip() else None,
                    new_file_path=new_path.strip() if new_path.strip() else None
                )
                
                if success:
                    return f"âœ… ç³»åˆ— {series_id} çš„çƒ§åˆ¶è§†é¢‘ä¿¡æ¯å·²æ›´æ–°"
                else:
                    return f"âŒ æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»åˆ—IDæ˜¯å¦å­˜åœ¨"
                    
            except Exception as e:
                LOG.error(f"æ›´æ–°çƒ§åˆ¶è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
                return f"âŒ æ›´æ–°å¤±è´¥: {str(e)}"

        def delete_series_func(series_id):
            """åˆ é™¤ç³»åˆ—"""
            if not series_id:
                return "è¯·è¾“å…¥æœ‰æ•ˆçš„ç³»åˆ—ID"
            
            try:
                success = db_manager.delete_series(int(series_id))
                if success:
                    return f"âœ… æˆåŠŸåˆ é™¤ç³»åˆ— {series_id}"
                else:
                    return f"âŒ åˆ é™¤å¤±è´¥ï¼Œç³»åˆ— {series_id} ä¸å­˜åœ¨"
            except Exception as e:
                LOG.error(f"åˆ é™¤ç³»åˆ—å¤±è´¥: {e}")
                return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}"

        def add_keyword_func(subtitle_id, keyword, phonetic, explanation):
            """æ·»åŠ å…³é”®è¯"""
            if not subtitle_id or not keyword.strip():
                return "âŒ è¯·å¡«å†™å­—å¹•IDå’Œå…³é”®è¯"
            
            try:
                keyword_data = [{
                    'key_word': keyword.strip(),
                    'phonetic_symbol': phonetic.strip() if phonetic else '',
                    'explain_text': explanation.strip() if explanation else ''
                }]
                
                keyword_ids = db_manager.create_keywords(int(subtitle_id), keyword_data)
                if keyword_ids:
                    return f"âœ… æˆåŠŸæ·»åŠ å…³é”®è¯: {keyword} (ID: {keyword_ids[0]})"
                else:
                    return "âŒ æ·»åŠ å¤±è´¥"
            except Exception as e:
                LOG.error(f"æ·»åŠ å…³é”®è¯å¤±è´¥: {e}")
                return f"âŒ æ·»åŠ å¤±è´¥: {str(e)}"

        def extract_keywords_ai(series_id):
            """ä½¿ç”¨AIæå–å…³é”®è¯"""
            if not series_id:
                return "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ç³»åˆ—ID", "âŒ è¯·è¾“å…¥ç³»åˆ—ID"
            
            try:
                # å¯¼å…¥å…³é”®è¯æå–å™¨
                from keyword_extractor import keyword_extractor
                
                # è·å–ç³»åˆ—å­—å¹•
                subtitles = db_manager.get_subtitles(int(series_id))
                if not subtitles:
                    return "âŒ è¯¥ç³»åˆ—æ²¡æœ‰å­—å¹•æ•°æ®", "æœªæ‰¾åˆ°å­—å¹•"
                
                # è¿‡æ»¤æœ‰è‹±æ–‡æ–‡æœ¬çš„å­—å¹•
                english_subtitles = [sub for sub in subtitles if sub.get('english_text', '').strip()]
                if not english_subtitles:
                    return "âŒ è¯¥ç³»åˆ—æ²¡æœ‰è‹±æ–‡å­—å¹•æ–‡æœ¬", "æ²¡æœ‰è‹±æ–‡æ–‡æœ¬"
                
                yield f"ğŸ”„ å¼€å§‹AIåˆ†æ...", f"å‡†å¤‡åˆ†æ {len(english_subtitles)} æ¡å­—å¹•"
                
                # ä½¿ç”¨æ‰¹é‡æå–æ¨¡å¼ï¼ˆæ›´é«˜æ•ˆï¼‰
                extracted_keywords = keyword_extractor.batch_extract_with_context(
                    english_subtitles, batch_size=3
                )
                
                if not extracted_keywords:
                    yield "âš ï¸ AIæœªæå–åˆ°å…³é”®è¯", "åˆ†æå®Œæˆï¼Œä½†æœªæ‰¾åˆ°é‡ç‚¹è¯æ±‡"
                    return
                
                yield f"ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...", f"æå–åˆ° {len(extracted_keywords)} ä¸ªå…³é”®è¯"
                
                # åˆ†ç»„ä¿å­˜åˆ°æ•°æ®åº“
                saved_count = 0
                for keyword in extracted_keywords:
                    subtitle_id = keyword['subtitle_id']
                    if subtitle_id:
                        keyword_data = [{
                            'key_word': keyword['key_word'],
                            'phonetic_symbol': keyword.get('phonetic_symbol', ''),
                            'explain_text': keyword.get('explain_text', '')
                        }]
                        
                        try:
                            db_manager.create_keywords(subtitle_id, keyword_data)
                            saved_count += 1
                        except Exception as e:
                            LOG.error(f"ä¿å­˜å…³é”®è¯å¤±è´¥: {e}")
                
                yield f"âœ… AIæå–å®Œæˆï¼", f"æˆåŠŸä¿å­˜ {saved_count} ä¸ªå…³é”®è¯åˆ°æ•°æ®åº“"
                
            except Exception as e:
                LOG.error(f"AIæå–å…³é”®è¯å¤±è´¥: {e}")
                yield f"âŒ æå–å¤±è´¥: {str(e)}", "å‘ç”Ÿé”™è¯¯"

        # ç»‘å®šäº‹ä»¶
        interface.load(
            fn=lambda: (update_statistics(), load_series_list()),
            outputs=[stats_display, series_table]
        )
        
        refresh_series_btn.click(
            fn=lambda: (update_statistics(), load_series_list()),
            outputs=[stats_display, series_table]
        )
        
        view_subtitles_btn.click(
            fn=load_subtitles_by_series,
            inputs=[selected_series_id],
            outputs=[subtitles_table]
        )
        
        load_subtitles_btn.click(
            fn=load_subtitles_by_series,
            inputs=[series_id_input],
            outputs=[subtitles_table]
        )
        
        search_btn.click(
            fn=search_keywords_func,
            inputs=[search_keyword_input],
            outputs=[keywords_table]
        )
        
        load_keywords_btn.click(
            fn=load_keywords_by_series,
            inputs=[keyword_series_id],
            outputs=[keywords_table]
        )
        
        delete_series_btn.click(
            fn=delete_series_func,
            inputs=[selected_series_id],
            outputs=[gr.Textbox(label="åˆ é™¤ç»“æœ", interactive=False)]
        )
        
        add_keyword_btn.click(
            fn=add_keyword_func,
            inputs=[add_subtitle_id, add_keyword, add_phonetic, add_explanation],
            outputs=[add_result]
        )
        
        extract_keywords_btn.click(
            fn=extract_keywords_ai,
            inputs=[keyword_series_id],
            outputs=[extract_status, extract_progress]
        )
        
        update_video_btn.click(
            fn=update_video_info_func,
            inputs=[update_series_id, update_new_name, update_new_path],
            outputs=[update_result]
        )
    
    return interface

if __name__ == "__main__":
    LOG.info("ğŸš€ å¯åŠ¨æ•°æ®åº“ç®¡ç†ç•Œé¢...")
    interface = create_database_interface()
    interface.queue().launch(
        server_name="0.0.0.0",
        server_port=7861,
        share=False,
        show_error=True
    ) 