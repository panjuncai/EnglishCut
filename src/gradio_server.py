import os
# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥è§£å†³ OpenMP å†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import gradio as gr
from openai_whisper import asr, save_lrc_file, save_srt_file
from logger import LOG

def process_audio_with_subtitles(audio_file, bilingual_mode, subtitle_format):
    """å¤„ç†éŸ³é¢‘æ–‡ä»¶å¹¶ç”Ÿæˆæ–‡æœ¬å’Œå­—å¹•æ–‡ä»¶"""
    try:
        if not audio_file or not os.path.exists(audio_file):
            return "è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", None, ""
        
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ ¼å¼
        file_ext = os.path.splitext(audio_file)[1].lower()
        if file_ext not in ['.wav', '.flac', '.mp3']:
            return "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼è¯·ä¸Šä¼  WAVã€FLAC æˆ– MP3 æ–‡ä»¶ã€‚", None, ""
        
        LOG.info(f"ğŸµ å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_file}")
        LOG.info(f"ğŸŒ åŒè¯­æ¨¡å¼: {'å¼€å¯' if bilingual_mode else 'å…³é—­'}")
        LOG.info(f"ğŸ“ å­—å¹•æ ¼å¼: {subtitle_format.upper()}")
        
        # ä½¿ç”¨ OpenAI Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
        result_data = asr(audio_file, return_bilingual=bilingual_mode)
        
        if isinstance(result_data, dict):
            english_text = result_data.get("english_text", "")
            chinese_text = result_data.get("chinese_text", "")
            
            # æ˜¾ç¤ºæ–‡æœ¬ï¼ˆåŒè¯­æ¨¡å¼æ˜¾ç¤ºåŒè¯­ï¼Œå•è¯­æ¨¡å¼æ˜¾ç¤ºè‹±æ–‡ï¼‰
            if bilingual_mode and chinese_text:
                display_text = f"ğŸ‡¬ğŸ‡§ è‹±æ–‡åŸæ–‡ï¼š\n{english_text}\n\nğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è¯‘ï¼š\n{chinese_text}"
            else:
                display_text = english_text
            
            # æ ¹æ®é€‰æ‹©çš„æ ¼å¼ç”Ÿæˆå­—å¹•æ–‡ä»¶
            subtitle_file_path = None
            if subtitle_format.lower() == "lrc":
                subtitle_file_path = save_lrc_file(result_data, audio_file)
            elif subtitle_format.lower() == "srt":
                subtitle_file_path = save_srt_file(result_data, audio_file)
            
            # ç”Ÿæˆå¤„ç†ä¿¡æ¯
            processing_time = result_data.get("processing_time", 0)
            chunks_count = len(result_data.get("chunks", []))
            
            info_text = f"""
ğŸ“Š å¤„ç†å®Œæˆï¼
â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.1f} ç§’
ğŸ“ è‹±æ–‡é•¿åº¦: {len(english_text)} å­—ç¬¦
ğŸŒ åŒè¯­æ¨¡å¼: {'âœ… å·²ç”Ÿæˆä¸­æ–‡ç¿»è¯‘' if bilingual_mode else 'âŒ ä»…è‹±æ–‡'}
ğŸ“„ å­—å¹•æ ¼å¼: {subtitle_format.upper()}
ğŸ• æ—¶é—´æˆ³æ®µæ•°: {chunks_count}
"""
            
            return display_text, subtitle_file_path, info_text
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬è¿”å›æ ¼å¼
            return str(result_data), None, "âš ï¸ æœªç”Ÿæˆæ—¶é—´æˆ³ä¿¡æ¯"
            
    except Exception as e:
        LOG.error(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
        return f"å¤„ç†å‡ºé”™ï¼š{str(e)}", None, ""

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(
    title="éŸ³é¢‘è½¬æ–‡å­— & å­—å¹•ç”Ÿæˆå™¨",
    css="""
    body { animation: fadeIn 2s; }
    @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
    .info-box { 
        background: #f0f8ff; 
        padding: 10px; 
        border-radius: 5px; 
        border-left: 4px solid #007acc; 
    }
    """
) as demo:
    # æ·»åŠ æ ‡é¢˜å’Œè¯´æ˜
    gr.Markdown("""
    # ğŸµ éŸ³é¢‘è½¬æ–‡å­— & å­—å¹•ç”Ÿæˆå™¨
    
    æ”¯æŒå°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºæ–‡å­—ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å­—å¹•æ–‡ä»¶ã€‚
    
    **æ”¯æŒæ ¼å¼**: WAVã€FLACã€MP3  
    **å­—å¹•æ ¼å¼**: LRCã€SRTï¼ˆæ”¯æŒåŒè¯­ï¼‰  
    **ç‰¹è‰²åŠŸèƒ½**: Mac M4 GPU åŠ é€Ÿã€GPT-4o-mini é«˜è´¨é‡ç¿»è¯‘
    
    **åŒè¯­ç¿»è¯‘**: ä½¿ç”¨ OpenAI GPT-4o-mini æä¾›é«˜è´¨é‡è‹±ä¸­ç¿»è¯‘
    """)

    with gr.Row():
        with gr.Column(scale=1):
            # æ–‡ä»¶ä¸Šä¼ 
            audio_input = gr.Audio(
                source="upload",
                type="filepath",
                label="ğŸ“ ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶",
                show_download_button=False
            )
            
            # åŒè¯­æ¨¡å¼é€‰æ‹©
            bilingual_checkbox = gr.Checkbox(
                label="ğŸŒ ç”Ÿæˆè‹±ä¸­åŒè¯­å­—å¹•",
                value=True,
                info="å¼€å¯åå°†ç”Ÿæˆè‹±æ–‡+ä¸­æ–‡æ ¼å¼çš„å­—å¹•"
            )
            
            # å­—å¹•æ ¼å¼é€‰æ‹©
            subtitle_format_select = gr.Dropdown(
                label="ğŸ“ é€‰æ‹©å­—å¹•æ ¼å¼",
                choices=["LRC", "SRT"],
                value="LRC",
                info="LRC: éŸ³ä¹æ’­æ”¾å™¨æ ¼å¼ [æ—¶é—´]æ–‡æœ¬ | SRT: è§†é¢‘æ’­æ”¾å™¨æ ¼å¼"
            )
            
            # å¤„ç†æŒ‰é’®
            process_btn = gr.Button(
                "ğŸš€ å¼€å§‹è¯†åˆ«", 
                variant="primary",
                size="lg"
            )
            
            # # å¤„ç†ä¿¡æ¯æ˜¾ç¤º
            # info_output = gr.Markdown(
            #     "ğŸ’¡ è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¼€å§‹å¤„ç†",
            #     elem_classes=["info-box"]
            # )
        
        with gr.Column(scale=2):
            # è¯†åˆ«ç»“æœæ–‡æœ¬
            text_output = gr.Textbox(
                label="ğŸ“ è¯†åˆ«ç»“æœ",
                placeholder="è¯†åˆ«ç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º...",
                lines=15,
                show_copy_button=True
            )
            
            # LRCæ–‡ä»¶ä¸‹è½½
            lrc_download = gr.File(
                label="ğŸ“„ ä¸‹è½½å­—å¹•æ–‡ä»¶",
                visible=False
            )
    
    # ç¤ºä¾‹æ–‡ä»¶ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    gr.Markdown("""
    ### ğŸ“Œ ä½¿ç”¨è¯´æ˜
    1. **è®¾ç½®APIå¯†é’¥**ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰: å¤åˆ¶ `env.example` ä¸º `.env` å¹¶å¡«å…¥æ‚¨çš„ OpenAI API å¯†é’¥
    2. ç‚¹å‡»"ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"é€‰æ‹©æ‚¨çš„éŸ³é¢‘æ–‡ä»¶
    3. é€‰æ‹©æ˜¯å¦å¼€å¯"ğŸŒ ç”Ÿæˆè‹±ä¸­åŒè¯­å­—å¹•"ï¼ˆæ¨èå¼€å¯ï¼‰
    4. é€‰æ‹©å­—å¹•æ ¼å¼ï¼š**LRC**ï¼ˆéŸ³ä¹æ’­æ”¾å™¨ï¼‰æˆ– **SRT**ï¼ˆè§†é¢‘æ’­æ”¾å™¨ï¼‰
    5. ç‚¹å‡»"å¼€å§‹è¯†åˆ«"è¿›è¡Œå¤„ç†ï¼ˆMac M4 ç”¨æˆ·å°†äº«å—GPUåŠ é€Ÿï¼‰
    6. ç­‰å¾…å¤„ç†å®Œæˆï¼ŒæŸ¥çœ‹è¯†åˆ«ç»“æœ
    7. ä¸‹è½½ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶ç”¨äºæ’­æ”¾å™¨
    
    ### ğŸ“ å­—å¹•æ ¼å¼è¯´æ˜
    - **LRCæ ¼å¼**: é€‚ç”¨äºéŸ³ä¹æ’­æ”¾å™¨ï¼Œæ ¼å¼ä¸º `[mm:ss.xx]æ­Œè¯å†…å®¹`
    - **SRTæ ¼å¼**: é€‚ç”¨äºè§†é¢‘æ’­æ”¾å™¨ï¼ŒåŒ…å«åºå·ã€æ—¶é—´æˆ³å’Œå­—å¹•å†…å®¹
    - **åŒè¯­æ¨¡å¼**: LRC æ˜¾ç¤ºä¸º `è‹±æ–‡ // ä¸­æ–‡`ï¼ŒSRT æ˜¾ç¤ºä¸ºä¸¤è¡Œï¼ˆè‹±æ–‡æ¢è¡Œä¸­æ–‡ï¼‰
    
    ### ğŸ”‘ åŒè¯­åŠŸèƒ½è®¾ç½®
    - éœ€è¦OpenAI APIå¯†é’¥æ‰èƒ½ä½¿ç”¨GPT-4o-miniç¿»è¯‘
    - å¤åˆ¶ `env.example` ä¸º `.env` 
    - å°† `OPENAI_API_KEY=sk-your-openai-api-key-here` æ›¿æ¢ä¸ºæ‚¨çš„çœŸå®å¯†é’¥
    - é‡å¯åº”ç”¨åç”Ÿæ•ˆ
    """)
    
    # ç»‘å®šäº‹ä»¶å¤„ç†
    # def update_interface(audio_file):
    #     """æ›´æ–°ç•Œé¢çŠ¶æ€"""
    #     if audio_file:
    #         return gr.update(visible=True), "ğŸ”„ ç‚¹å‡»å¼€å§‹è¯†åˆ«æŒ‰é’®å¤„ç†éŸ³é¢‘..."
    #     else:
    #         return gr.update(visible=False), "ğŸ’¡ è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¼€å§‹å¤„ç†"
    
    def process_and_update(audio_file, bilingual_mode, subtitle_format):
        """å¤„ç†éŸ³é¢‘å¹¶æ›´æ–°ç•Œé¢"""
        text, subtitle_file, info = process_audio_with_subtitles(audio_file, bilingual_mode, subtitle_format)
        
        if subtitle_file and os.path.exists(subtitle_file):
            return (
                text,
                gr.update(value=subtitle_file, visible=True),
                info
            )
        else:
            return (
                text,
                gr.update(visible=False),
                info if info else "âŒ å¤„ç†å¤±è´¥"
            )
    
    # äº‹ä»¶ç»‘å®š
    audio_input.change(
        # fn=update_interface,
        inputs=[audio_input],
        outputs=[lrc_download]
    )
    
    process_btn.click(
        fn=process_and_update,
        inputs=[audio_input, bilingual_checkbox, subtitle_format_select],
        outputs=[text_output, lrc_download]
    )

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    # å¯åŠ¨Gradioåº”ç”¨
    demo.queue().launch(
        share=False,
        server_name="127.0.0.1",
        server_port=7860,
        show_error=True
    )