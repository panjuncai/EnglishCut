#!/usr/bin/env python3
"""
å­—å¹•æ™ºèƒ½åˆ‡åˆ†å™¨
å°†é•¿å¥å­åˆ‡åˆ†æˆé€‚åˆæ‰‹æœºå±å¹•æ˜¾ç¤ºçš„çŸ­å¥ï¼Œç‰¹åˆ«é’ˆå¯¹æŠ–éŸ³ç­‰çŸ­è§†é¢‘å¹³å°ä¼˜åŒ–
"""

import re
from typing import List, Dict, Tuple
from logger import LOG

class SubtitleSplitter:
    """å­—å¹•æ™ºèƒ½åˆ‡åˆ†å™¨ - åŸºäºè¯­ä¹‰å•å…ƒçš„ç²¾å‡†åˆ‡åˆ†"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ‡åˆ†å™¨"""
        
        # è‹±æ–‡è¿è¯å’Œåˆ†å‰²æ ‡è®° - æŒ‰ä¼˜å…ˆçº§æ’åº
        self.english_connectors = [
            'and', 'but', 'or', 'so', 'yet', 'for', 'nor',  # å¹¶åˆ—è¿è¯
            'because', 'since', 'although', 'while', 'when', 'where', 'if',  # ä»å±è¿è¯
            'however', 'therefore', 'moreover', 'furthermore', 'nevertheless'  # å‰¯è¯è¿è¯
        ]
        
        # è‹±æ–‡æ ‡ç‚¹åˆ†å‰²ç¬¦
        self.english_punctuation = [',', ';', ':', '-', 'â€“', 'â€”', '(', ')', '[', ']']
        
        # å¥å­ç»“æŸç¬¦
        self.sentence_endings = ['.', '!', '?']
        
        # ä¸­æ–‡æ ‡ç‚¹ç¬¦å·å¯¹åº”
        self.chinese_punctuation_map = {
            ',': 'ï¼Œ',
            ';': 'ï¼›', 
            ':': 'ï¼š',
            '.': 'ã€‚',
            '!': 'ï¼',
            '?': 'ï¼Ÿ',
            '(': 'ï¼ˆ',
            ')': 'ï¼‰',
            '[': 'ã€',
            ']': 'ã€‘'
        }
        
        # ä¸­æ–‡è¿æ¥è¯
        self.chinese_connectors = [
            'å’Œ', 'è€Œä¸”', 'ä½†æ˜¯', 'æˆ–è€…', 'æ‰€ä»¥', 'å› ä¸º', 'è™½ç„¶', 'å½“', 'å¦‚æœ', 'ç„¶å', 'æ¥ç€', 'äºæ˜¯'
        ]
        
        LOG.info("ğŸ”§ è¯­ä¹‰å•å…ƒå­—å¹•åˆ‡åˆ†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def split_english_text(self, text: str, start_time: float, end_time: float) -> List[Dict]:
        """
        åŸºäºè¯­ä¹‰å•å…ƒåˆ‡åˆ†è‹±æ–‡æ–‡æœ¬
        
        å‚æ•°:
        - text: åŸå§‹è‹±æ–‡æ–‡æœ¬
        - start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
        - end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
        
        è¿”å›:
        - List[Dict]: åˆ‡åˆ†åçš„å­—å¹•æ®µè½åˆ—è¡¨
        """
        if not text.strip():
            return []
        
        # å»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text.strip())
        
        # åŸºäºè¯­ä¹‰å•å…ƒåˆ‡åˆ†
        segments = self._split_by_semantic_units(text)
        
        # è®¡ç®—æ—¶é—´åˆ†é…
        return self._assign_timestamps(segments, start_time, end_time)
    
    def split_chinese_text(self, text: str, start_time: float, end_time: float) -> List[Dict]:
        """
        åˆ‡åˆ†ä¸­æ–‡æ–‡æœ¬
        
        å‚æ•°:
        - text: åŸå§‹ä¸­æ–‡æ–‡æœ¬
        - start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
        - end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
        
        è¿”å›:
        - List[Dict]: åˆ‡åˆ†åçš„å­—å¹•æ®µè½åˆ—è¡¨
        """
        if not text.strip():
            return []
        
        # å»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', '', text.strip())
        
        # æŒ‰å¥å­åˆ†å‰²
        sentences = self._split_chinese_by_sentences(text)
        
        # æŒ‰é•¿åº¦è¿›ä¸€æ­¥åˆ‡åˆ†
        segments = []
        for sentence in sentences:
            if len(sentence) <= self.max_chars_per_line:
                segments.append(sentence)
            else:
                # éœ€è¦è¿›ä¸€æ­¥åˆ‡åˆ†
                sub_segments = self._split_long_chinese_sentence(sentence)
                segments.extend(sub_segments)
        
        # è®¡ç®—æ—¶é—´åˆ†é…
        return self._assign_timestamps(segments, start_time, end_time)
    
    def split_bilingual_text(self, english_text: str, chinese_text: str, 
                           start_time: float, end_time: float) -> List[Dict]:
        """
        åˆ‡åˆ†åŒè¯­æ–‡æœ¬ - ä¿æŒè¯­ä¹‰å•å…ƒå¯¹åº”
        
        å‚æ•°:
        - english_text: è‹±æ–‡æ–‡æœ¬
        - chinese_text: ä¸­æ–‡æ–‡æœ¬
        - start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
        - end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
        
        è¿”å›:
        - List[Dict]: åˆ‡åˆ†åçš„åŒè¯­å­—å¹•æ®µè½åˆ—è¡¨
        """
        if not english_text.strip() and not chinese_text.strip():
            return []
        
        # åŸºäºè‹±æ–‡çš„è¯­ä¹‰å•å…ƒåˆ‡åˆ†ï¼Œç„¶ååŒæ­¥åˆ‡åˆ†ä¸­æ–‡
        english_segments = self._split_by_semantic_units(english_text) if english_text else []
        chinese_segments = self._split_chinese_by_english_units(chinese_text, english_segments) if chinese_text else []
        
        # å¯¹é½åŒè¯­æ®µè½
        aligned_segments = self._align_bilingual_segments(english_segments, chinese_segments)
        
        # è®¡ç®—æ—¶é—´åˆ†é…
        return self._assign_timestamps_bilingual(aligned_segments, start_time, end_time)
    
    def _split_by_semantic_units(self, text: str) -> List[str]:
        """åŸºäºè¯­ä¹‰å•å…ƒåˆ‡åˆ†è‹±æ–‡æ–‡æœ¬"""
        if not text.strip():
            return []
        
        segments = []
        
        # é¦–å…ˆæŒ‰å¥å­åˆ†å‰²
        sentences = self._split_sentences(text)
        
        for sentence in sentences:
            # å¯¹æ¯ä¸ªå¥å­è¿›è¡Œè¯­ä¹‰å•å…ƒåˆ‡åˆ†
            units = self._split_sentence_to_units(sentence)
            segments.extend(units)
        
        return [seg.strip() for seg in segments if seg.strip()]
    
    def _split_sentences(self, text: str) -> List[str]:
        """æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬"""
        sentences = []
        current_sentence = ""
        
        for char in text:
            current_sentence += char
            if char in self.sentence_endings:
                sentences.append(current_sentence.strip())
                current_sentence = ""
        
        # å¤„ç†æœ€åä¸€ä¸ªå¥å­
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        return [s for s in sentences if s]
    
    def _split_sentence_to_units(self, sentence: str) -> List[str]:
        """å°†å•ä¸ªå¥å­åˆ†å‰²ä¸ºè¯­ä¹‰å•å…ƒ"""
        if not sentence.strip():
            return []
        
        units = []
        words = sentence.split()
        current_unit = []
        
        i = 0
        while i < len(words):
            word = words[i]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿è¯ï¼ˆéœ€è¦å¼€å§‹æ–°å•å…ƒï¼‰
            if word.lower() in self.english_connectors and current_unit:
                # ä¿å­˜å½“å‰å•å…ƒ
                units.append(' '.join(current_unit))
                current_unit = [word]
            else:
                current_unit.append(word)
            
            # æ£€æŸ¥æ ‡ç‚¹ç¬¦å·
            if any(punct in word for punct in self.english_punctuation):
                if current_unit:
                    units.append(' '.join(current_unit))
                    current_unit = []
            
            i += 1
        
        # æ·»åŠ æœ€åä¸€ä¸ªå•å…ƒ
        if current_unit:
            units.append(' '.join(current_unit))
        
        return units
    
    def _split_chinese_by_english_units(self, chinese_text: str, english_segments: List[str]) -> List[str]:
        """æ ¹æ®è‹±æ–‡è¯­ä¹‰å•å…ƒåŒæ­¥åˆ‡åˆ†ä¸­æ–‡æ–‡æœ¬"""
        if not chinese_text.strip() or not english_segments:
            return []
        
        # ç®€å•ç­–ç•¥ï¼šæŒ‰è‹±æ–‡æ®µè½æ•°é‡ç­‰æ¯”ä¾‹åˆ†å‰²ä¸­æ–‡
        # è¿™é‡Œå¯ä»¥åç»­ä¼˜åŒ–ä¸ºåŸºäºç¿»è¯‘å¯¹åº”å…³ç³»çš„ç²¾ç¡®åˆ‡åˆ†
        
        chinese_text = chinese_text.strip()
        num_segments = len(english_segments)
        
        if num_segments == 1:
            return [chinese_text]
        
        # å¯»æ‰¾ä¸­æ–‡çš„è‡ªç„¶åˆ†å‰²ç‚¹
        chinese_segments = []
        
        # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†ä¸­æ–‡
        segments = self._split_chinese_by_punctuation(chinese_text)
        
        if len(segments) >= num_segments:
            # å¦‚æœä¸­æ–‡æ®µè½æ¯”è‹±æ–‡å¤šï¼Œåˆå¹¶ä¸€äº›æ®µè½
            step = len(segments) / num_segments
            chinese_segments = []
            for i in range(num_segments):
                start_idx = int(i * step)
                end_idx = int((i + 1) * step) if i < num_segments - 1 else len(segments)
                combined = ''.join(segments[start_idx:end_idx])
                if combined:
                    chinese_segments.append(combined)
        else:
            # å¦‚æœä¸­æ–‡æ®µè½æ¯”è‹±æ–‡å°‘ï¼Œå°è¯•æ™ºèƒ½åˆ†å‰²
            chinese_segments = _smart_split_chinese(chinese_text, num_segments)
        
        # ç¡®ä¿è¿”å›æ­£ç¡®æ•°é‡çš„æ®µè½
        while len(chinese_segments) < num_segments:
            chinese_segments.append("")
        
        return chinese_segments[:num_segments]
    
    def _split_chinese_by_punctuation(self, text: str) -> List[str]:
        """æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ä¸­æ–‡æ–‡æœ¬"""
        if not text:
            return []
        
        chinese_punctuation = ['ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'ï¼š', 'ã€']
        segments = []
        current_segment = ""
        
        for char in text:
            current_segment += char
            if char in chinese_punctuation:
                if current_segment.strip():
                    segments.append(current_segment.strip())
                current_segment = ""
        
        # æ·»åŠ æœ€åä¸€æ®µ
        if current_segment.strip():
            segments.append(current_segment.strip())
        
        return segments
    
    def _split_long_sentence(self, sentence: str) -> List[str]:
        """åˆ‡åˆ†è¿‡é•¿çš„è‹±æ–‡å¥å­"""
        words = sentence.split()
        segments = []
        current_segment = []
        
        for word in words:
            # æ£€æŸ¥æ·»åŠ å½“å‰å•è¯åæ˜¯å¦è¶…é•¿
            test_segment = current_segment + [word]
            test_text = ' '.join(test_segment)
            
            if (len(test_segment) <= self.max_words_per_line and 
                len(test_text) <= self.max_chars_per_line):
                current_segment.append(word)
            else:
                # ä¿å­˜å½“å‰æ®µè½ï¼Œå¼€å§‹æ–°æ®µè½
                if current_segment:
                    segments.append(' '.join(current_segment))
                current_segment = [word]
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½
        if current_segment:
            segments.append(' '.join(current_segment))
        
        return segments
    
    def _split_long_chinese_sentence(self, sentence: str) -> List[str]:
        """åˆ‡åˆ†è¿‡é•¿çš„ä¸­æ–‡å¥å­"""
        segments = []
        current_segment = ""
        
        # é¦–å…ˆå°è¯•æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²
        parts = []
        current_part = ""
        
        for char in sentence:
            current_part += char
            if char in self.chinese_phrase_breaks:
                parts.append(current_part)
                current_part = ""
        
        if current_part:
            parts.append(current_part)
        
        # å¦‚æœæ²¡æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œç›´æ¥æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†
        if not parts or len(parts) == 1:
            for i in range(0, len(sentence), self.max_chars_per_line):
                segment = sentence[i:i + self.max_chars_per_line]
                if segment:
                    segments.append(segment)
        else:
            # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†çš„ç»“æœè¿›è¡Œç»„åˆ
            for part in parts:
                if len(current_segment + part) <= self.max_chars_per_line:
                    current_segment += part
                else:
                    if current_segment:
                        segments.append(current_segment)
                    current_segment = part
            
            if current_segment:
                segments.append(current_segment)
        
        return segments
    
    def _split_text_only(self, text: str) -> List[str]:
        """åªåˆ‡åˆ†æ–‡æœ¬ï¼Œä¸åˆ†é…æ—¶é—´"""
        if not text.strip():
            return []
        
        text = re.sub(r'\s+', ' ', text.strip())
        sentences = self._split_by_sentences(text)
        
        segments = []
        for sentence in sentences:
            if len(sentence.split()) <= self.max_words_per_line and len(sentence) <= self.max_chars_per_line:
                segments.append(sentence)
            else:
                sub_segments = self._split_long_sentence(sentence)
                segments.extend(sub_segments)
        
        return segments
    
    def _split_chinese_text_only(self, text: str) -> List[str]:
        """åªåˆ‡åˆ†ä¸­æ–‡æ–‡æœ¬ï¼Œä¸åˆ†é…æ—¶é—´"""
        if not text.strip():
            return []
        
        text = re.sub(r'\s+', '', text.strip())
        sentences = self._split_chinese_by_sentences(text)
        
        segments = []
        for sentence in sentences:
            if len(sentence) <= self.max_chars_per_line:
                segments.append(sentence)
            else:
                sub_segments = self._split_long_chinese_sentence(sentence)
                segments.extend(sub_segments)
        
        return segments
    
    def _align_bilingual_segments(self, english_segments: List[str], chinese_segments: List[str]) -> List[Dict]:
        """å¯¹é½åŒè¯­æ®µè½"""
        aligned = []
        max_len = max(len(english_segments), len(chinese_segments))
        
        for i in range(max_len):
            english = english_segments[i] if i < len(english_segments) else ""
            chinese = chinese_segments[i] if i < len(chinese_segments) else ""
            
            if english or chinese:
                aligned.append({
                    "english": english,
                    "chinese": chinese
                })
        
        return aligned
    
    def _assign_timestamps(self, segments: List[str], start_time: float, end_time: float) -> List[Dict]:
        """ä¸ºå•è¯­æ®µè½åˆ†é…æ—¶é—´æˆ³"""
        if not segments:
            return []
        
        total_chars = sum(len(seg) for seg in segments)
        duration = end_time - start_time
        
        result = []
        current_time = start_time
        
        for i, segment in enumerate(segments):
            # æŒ‰å­—ç¬¦æ•°æ¯”ä¾‹åˆ†é…æ—¶é—´
            segment_ratio = len(segment) / total_chars if total_chars > 0 else 1 / len(segments)
            segment_duration = duration * segment_ratio
            
            # ç¡®ä¿æœ€åä¸€ä¸ªæ®µè½ç»“æŸæ—¶é—´æ­£ç¡®
            if i == len(segments) - 1:
                segment_end_time = end_time
            else:
                segment_end_time = current_time + segment_duration
            
            result.append({
                "text": segment,
                "timestamp": [current_time, segment_end_time]
            })
            
            current_time = segment_end_time
        
        return result
    
    def _assign_timestamps_bilingual(self, segments: List[Dict], start_time: float, end_time: float) -> List[Dict]:
        """ä¸ºåŒè¯­æ®µè½åˆ†é…æ—¶é—´æˆ³"""
        if not segments:
            return []
        
        # è®¡ç®—æ€»æƒé‡ï¼ˆä¼˜å…ˆè€ƒè™‘è‹±æ–‡å­—ç¬¦æ•°ï¼‰
        total_weight = 0
        for seg in segments:
            english_chars = len(seg.get("english", ""))
            chinese_chars = len(seg.get("chinese", ""))
            weight = max(english_chars, chinese_chars)  # å–è¾ƒé•¿çš„æ–‡æœ¬ä½œä¸ºæƒé‡
            total_weight += weight
        
        duration = end_time - start_time
        result = []
        current_time = start_time
        
        for i, segment in enumerate(segments):
            english_chars = len(segment.get("english", ""))
            chinese_chars = len(segment.get("chinese", ""))
            segment_weight = max(english_chars, chinese_chars)
            
            # æŒ‰æƒé‡åˆ†é…æ—¶é—´
            segment_ratio = segment_weight / total_weight if total_weight > 0 else 1 / len(segments)
            segment_duration = duration * segment_ratio
            
            # ç¡®ä¿æœ€åä¸€ä¸ªæ®µè½ç»“æŸæ—¶é—´æ­£ç¡®
            if i == len(segments) - 1:
                segment_end_time = end_time
            else:
                segment_end_time = current_time + segment_duration
            
            result.append({
                "english": segment.get("english", ""),
                "chinese": segment.get("chinese", ""),
                "timestamp": [current_time, segment_end_time]
            })
            
            current_time = segment_end_time
        
        return result

def split_subtitle_chunks(chunks: List[Dict], is_bilingual: bool = False, **kwargs) -> List[Dict]:
    """
    åŸºäºè¯­ä¹‰å•å…ƒæ™ºèƒ½åˆ‡åˆ†å­—å¹•å—ï¼Œè®©ä¸­è‹±æ–‡ç²¾ç¡®å¯¹åº”
    
    å‚æ•°:
    - chunks: åŸå§‹å­—å¹•å—åˆ—è¡¨
    - is_bilingual: æ˜¯å¦ä¸ºåŒè¯­å­—å¹•
    
    è¿”å›:
    - List[Dict]: åˆ‡åˆ†åçš„å­—å¹•å—åˆ—è¡¨
    """
    if not chunks:
        return []
    
    splitter = SubtitleSplitter()
    result_chunks = []
    
    LOG.info(f"ğŸ”§ å¼€å§‹è¯­ä¹‰å•å…ƒåˆ‡åˆ†: {len(chunks)} ä¸ªåŸå§‹ç‰‡æ®µ, åŒè¯­æ¨¡å¼: {is_bilingual}")
    
    for chunk in chunks:
        timestamp = chunk.get("timestamp", [None, None])
        if timestamp[0] is None or timestamp[1] is None:
            continue
        
        start_time, end_time = timestamp
        
        if is_bilingual:
            # åŒè¯­æ¨¡å¼
            english_text = chunk.get("english", "")
            chinese_text = chunk.get("chinese", "")
            
            if english_text or chinese_text:
                split_segments = splitter.split_bilingual_text(
                    english_text, chinese_text, start_time, end_time
                )
                
                for segment in split_segments:
                    result_chunks.append({
                        "english": segment["english"],
                        "chinese": segment["chinese"],
                        "timestamp": segment["timestamp"]
                    })
        
        else:
            # å•è¯­æ¨¡å¼
            text = chunk.get("text", "")
            
            if text:
                split_segments = splitter.split_english_text(text, start_time, end_time)
                
                for segment in split_segments:
                    result_chunks.append({
                        "text": segment["text"],
                        "timestamp": segment["timestamp"]
                    })
    
    LOG.info(f"âœ… è¯­ä¹‰å•å…ƒåˆ‡åˆ†å®Œæˆ: {len(result_chunks)} ä¸ªæ–°ç‰‡æ®µ")
    return result_chunks

# åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ æ™ºèƒ½ä¸­æ–‡åˆ‡åˆ†æ–¹æ³•
def _smart_split_chinese(chinese_text: str, num_segments: int) -> List[str]:
    """æ™ºèƒ½åˆ†å‰²ä¸­æ–‡æ–‡æœ¬ä¸ºæŒ‡å®šæ•°é‡çš„æ®µè½"""
    if not chinese_text or num_segments <= 0:
        return []
    
    if num_segments == 1:
        return [chinese_text]
    
    # é¦–å…ˆå°è¯•æ‰¾åˆ°è‡ªç„¶çš„åˆ†å‰²ç‚¹ï¼ˆæ ‡ç‚¹ç¬¦å·ï¼‰
    chinese_punctuation = ['ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'ï¼š', 'ã€']
    potential_splits = []
    
    for i, char in enumerate(chinese_text):
        if char in chinese_punctuation:
            potential_splits.append(i + 1)  # +1 åŒ…å«æ ‡ç‚¹ç¬¦å·
    
    if len(potential_splits) >= num_segments - 1:
        # é€‰æ‹©æœ€å‡åŒ€åˆ†å¸ƒçš„åˆ†å‰²ç‚¹
        step = len(potential_splits) / (num_segments - 1)
        selected_splits = []
        for i in range(num_segments - 1):
            idx = int(i * step)
            if idx < len(potential_splits):
                selected_splits.append(potential_splits[idx])
        
        # æ ¹æ®é€‰æ‹©çš„åˆ†å‰²ç‚¹åˆ†å‰²æ–‡æœ¬
        segments = []
        start = 0
        for split_pos in selected_splits:
            segments.append(chinese_text[start:split_pos])
            start = split_pos
        segments.append(chinese_text[start:])  # æœ€åä¸€æ®µ
        
        return [seg for seg in segments if seg]
    
    else:
        # æ²¡æœ‰è¶³å¤Ÿçš„æ ‡ç‚¹ç¬¦å·ï¼ŒæŒ‰å­—ç¬¦æ•°å¹³å‡åˆ†å‰²
        char_per_segment = len(chinese_text) // num_segments
        segments = []
        for i in range(num_segments):
            start = i * char_per_segment
            if i == num_segments - 1:
                end = len(chinese_text)
            else:
                end = (i + 1) * char_per_segment
            segment = chinese_text[start:end]
            if segment:
                segments.append(segment)
        
        return segments 